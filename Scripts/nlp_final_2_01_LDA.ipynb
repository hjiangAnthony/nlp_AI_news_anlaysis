{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 12 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from pprint import pprint\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import numpy as np\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(nb_workers=12, progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/anthony/projects/nlp_runtime\n"
     ]
    }
   ],
   "source": [
    "#!pwd\n",
    "import os\n",
    "\n",
    "# Google Bucket\n",
    "# file name checkpoint_0512_sent_split.parquet\n",
    "path_bucket = 'gs://msca-sp23-bucket/nlp_data'\n",
    "bucket_read = path_bucket + '/' + 'checkpoint_0523_cleaned_filtered_data.parquet'\n",
    "runtime_path = '/home/anthony/projects/nlp_runtime'\n",
    "\n",
    "os.chdir(runtime_path)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora, models\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk as nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting en-core-web-md==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.5.0/en_core_web_md-3.5.0-py3-none-any.whl (42.8 MB)\n",
      "\u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 42.8/42.8 MB 25.6 MB/s eta 0:00:00\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /opt/conda/envs/nlp/lib/python3.10/site-packages (from en-core-web-md==3.5.0) (3.5.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/envs/nlp/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/envs/nlp/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/envs/nlp/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/envs/nlp/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/envs/nlp/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /opt/conda/envs/nlp/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (8.1.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/envs/nlp/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.1.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/envs/nlp/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.4.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/envs/nlp/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /opt/conda/envs/nlp/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /opt/conda/envs/nlp/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/envs/nlp/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/envs/nlp/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/anthony/.local/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.24.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/envs/nlp/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.29.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /opt/conda/envs/nlp/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.10.7)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/envs/nlp/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/nlp/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (67.7.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/nlp/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/envs/nlp/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/envs/nlp/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/nlp/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/nlp/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/nlp/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/nlp/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2023.5.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/envs/nlp/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/envs/nlp/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/envs/nlp/lib/python3.10/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/envs/nlp/lib/python3.10/site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.1.2)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import spacy.cli\n",
    "spacy.cli.download(\"en_core_web_md\")\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/anthony/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/anthony/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /home/anthony/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to /home/anthony/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/anthony/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df_raw = pd.read_parquet(bucket_read, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw data shape(185479, 4)\n",
      "sample shape(50000, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>text_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95601</th>\n",
       "      <td>https://www.wkyt.com/prnewswire/2022/06/14/windwards-first-of-its-kind-ai-model-creates-new-standard-eta-prediction-accuracy-critical-mitigating-supply-chain-disruptions/</td>\n",
       "      <td>2022-06-14</td>\n",
       "      <td>Windward's First-of-its-Kind AI Model Creates a New Standard of ETA Prediction Accuracy Critical to Mitigating Supply Chain Disruptions</td>\n",
       "      <td>Windward's First of its Kind AI Model Creates a New Standard of ETA Prediction Accuracy Critical to Mitigating Supply Chain Disruptions Skip to    NewscastsEveryday   Health DivideWKYT   CamsClosings    Championship 2022All BlueHigh School Game TimeMingua s Athlete of the WeekSports  s Corner Off the BenchContact UsSubmit a News TipMeet the TeamAdvertising InformationJobs at WKYTNews AlertsSubmit Photos and VideosGray DC BureauInvestigate TVCommunityAloha MondaysBG H G TV  of KindnessCommuni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                              url   \n",
       "95601  https://www.wkyt.com/prnewswire/2022/06/14/windwards-first-of-its-kind-ai-model-creates-new-standard-eta-prediction-accuracy-critical-mitigating-supply-chain-disruptions/  \\\n",
       "\n",
       "             date   \n",
       "95601  2022-06-14  \\\n",
       "\n",
       "                                                                                                                                         title   \n",
       "95601  Windward's First-of-its-Kind AI Model Creates a New Standard of ETA Prediction Accuracy Critical to Mitigating Supply Chain Disruptions  \\\n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              text_cleaned  \n",
       "95601  Windward's First of its Kind AI Model Creates a New Standard of ETA Prediction Accuracy Critical to Mitigating Supply Chain Disruptions Skip to    NewscastsEveryday   Health DivideWKYT   CamsClosings    Championship 2022All BlueHigh School Game TimeMingua s Athlete of the WeekSports  s Corner Off the BenchContact UsSubmit a News TipMeet the TeamAdvertising InformationJobs at WKYTNews AlertsSubmit Photos and VideosGray DC BureauInvestigate TVCommunityAloha MondaysBG H G TV  of KindnessCommuni...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a sample\n",
    "df = df_raw.sample(50000, random_state=42)\n",
    "\n",
    "print(f'raw data shape{df_raw.shape}')\n",
    "print(f'sample shape{df.shape}')\n",
    "df.head(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA, on overall topics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Prep\n",
    "\n",
    "I want to utilize parallelization as much as possile to save time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 181 µs, sys: 2.67 ms, total: 2.85 ms\n",
      "Wall time: 2.01 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "\n",
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "stop_words = stopwords.words('english')\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c3503b3be4c4144a322ff15fc69e44e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=4167), Label(value='0 / 4167'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# select the text\n",
    "df_text = df[['text_cleaned']]\n",
    "#df_title = df['title']\n",
    "\n",
    "# remove punctuation and numbers using parallel_apply\n",
    "df_text['text_cleaned'] = df_text['text_cleaned'].parallel_apply(lambda x: re.sub('[^A-Za-z]+', ' ', x))\n",
    "#df_title['title_cleaned'] = df_title.parallel_apply(lambda x: re.sub('[^A-Za-z]+', ' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 49810 entries, 95601 to 127958\n",
      "Data columns (total 1 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   text_cleaned  49810 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 778.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# drop na and duplicates\n",
    "df_text = df_text.dropna().drop_duplicates()\n",
    "# convert to str type\n",
    "df_text['text_cleaned'] = df_text['text_cleaned'].astype(str)\n",
    "df_text.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02eb0b495c9849989bfefebedf3fb312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=4151), Label(value='0 / 4151'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# save a copy\n",
    "df_text_before = df_text.copy()\n",
    "\n",
    "# define a function to handle errors\n",
    "def handle_errors(func):\n",
    "    def wrapper(x):\n",
    "        try:\n",
    "            return func(x)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row: {x}\")\n",
    "            return np.nan\n",
    "    return wrapper\n",
    "\n",
    "# define the remove_stopwords function with the handle_errors decorator\n",
    "@handle_errors\n",
    "def remove_stopwords(row): \n",
    "    return [i for i in simple_preprocess(row) if i not in stopwords.words('english')]\n",
    "\n",
    "# apply remove_stopwords function with try/except\n",
    "df_text['text_cleaned'] = df_text['text_cleaned'].parallel_apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95601</th>\n",
       "      <td>[windward, first, kind, ai, model, creates, new, standard, eta, prediction, accuracy, critical, mitigating, supply, chain, disruptions, skip, health, dividewkyt, camsclosings, championship, bluehigh, school, game, timemingua, athlete, weeksports, corner, benchcontact, ussubmit, news, tipmeet, teamadvertising, informationjobs, wkytnews, alertssubmit, photos, videosgray, dc, mondaysbg, tv, starssponsored, storieswkyt, summer, grillin, sponsored, pepsitv, listingscircle, country, music, lifesty...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176291</th>\n",
       "      <td>[engineer, claimed, google, ai, thoughts, feelings, placed, leave, newsbreaksign, arttv, seriesbooks, dancebehind, viral, artstv, musichip, healthhealth, servicesmental, healthdiseases, sportspremier, safetypublic, advicefamily, rentlabor, issuestrouble, scienceearth, nationsmiddle, locations, channels, topics, people, inwate, follow, followers, post, viewsaboutwate, side, provides, latest, news, weather, sports, coverage, knoxville, east, tennessee, vitelloin, article, google, ai, software,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51870</th>\n",
       "      <td>[flex, logix, announces, eflx, efpga, nnmax, ai, inference, ip, model, support, veloce, strato, emulation, platform, mentor, home, search, silicon, ip, search, verification, ip, latest, news, industry, articles, industry, expert, blogs, videos, slides, menu, design, reuse, subscribe, soc, news, alert, design, reuse, silicon, ip, analog, mixed, signal, storage, controller, phy, graphic, peripheral, interface, controller, phy, processors, memory, logic, library, security, multimedia, wireline,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183511</th>\n",
       "      <td>[vinsolutions, virtual, assistant, vinessa, uses, ai, help, salespeople, pursue, convert, leads, tight, market, resources, blog, journalists, log, sign, data, privacy, typing, field, list, search, results, appear, automatically, updated, type, searching, content, results, found, please, change, search, terms, try, news, releases, public, company, english, auto, automotive, transportation, aerospace, defense, air, freight, airlines, aviation, automotive, maritime, shipbuilding, railroads, int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131260</th>\n",
       "      <td>[nab, adobe, unveils, plans, ai, tools, video, news, broadcast, site, uses, cookies, using, site, agreeing, privacy, cookie, policy, skip, main, contentskip, navigation, hot, survey, ratingssvods, broadcast, mast, search, site, search, site, back, parent, navigation, item, ratings, back, parent, navigation, item, premium, back, parent, navigation, item, features, back, parent, navigation, item, international, homebroadcast, awards, best, places, work, tv, indie, survey, broadcast, digital, a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               text_cleaned\n",
       "95601   [windward, first, kind, ai, model, creates, new, standard, eta, prediction, accuracy, critical, mitigating, supply, chain, disruptions, skip, health, dividewkyt, camsclosings, championship, bluehigh, school, game, timemingua, athlete, weeksports, corner, benchcontact, ussubmit, news, tipmeet, teamadvertising, informationjobs, wkytnews, alertssubmit, photos, videosgray, dc, mondaysbg, tv, starssponsored, storieswkyt, summer, grillin, sponsored, pepsitv, listingscircle, country, music, lifesty...\n",
       "176291  [engineer, claimed, google, ai, thoughts, feelings, placed, leave, newsbreaksign, arttv, seriesbooks, dancebehind, viral, artstv, musichip, healthhealth, servicesmental, healthdiseases, sportspremier, safetypublic, advicefamily, rentlabor, issuestrouble, scienceearth, nationsmiddle, locations, channels, topics, people, inwate, follow, followers, post, viewsaboutwate, side, provides, latest, news, weather, sports, coverage, knoxville, east, tennessee, vitelloin, article, google, ai, software,...\n",
       "51870   [flex, logix, announces, eflx, efpga, nnmax, ai, inference, ip, model, support, veloce, strato, emulation, platform, mentor, home, search, silicon, ip, search, verification, ip, latest, news, industry, articles, industry, expert, blogs, videos, slides, menu, design, reuse, subscribe, soc, news, alert, design, reuse, silicon, ip, analog, mixed, signal, storage, controller, phy, graphic, peripheral, interface, controller, phy, processors, memory, logic, library, security, multimedia, wireline,...\n",
       "183511  [vinsolutions, virtual, assistant, vinessa, uses, ai, help, salespeople, pursue, convert, leads, tight, market, resources, blog, journalists, log, sign, data, privacy, typing, field, list, search, results, appear, automatically, updated, type, searching, content, results, found, please, change, search, terms, try, news, releases, public, company, english, auto, automotive, transportation, aerospace, defense, air, freight, airlines, aviation, automotive, maritime, shipbuilding, railroads, int...\n",
       "131260  [nab, adobe, unveils, plans, ai, tools, video, news, broadcast, site, uses, cookies, using, site, agreeing, privacy, cookie, policy, skip, main, contentskip, navigation, hot, survey, ratingssvods, broadcast, mast, search, site, search, site, back, parent, navigation, item, ratings, back, parent, navigation, item, premium, back, parent, navigation, item, features, back, parent, navigation, item, international, homebroadcast, awards, best, places, work, tv, indie, survey, broadcast, digital, a..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### titleza LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 1s, sys: 1.48 s, total: 2min 3s\n",
      "Wall time: 2min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# tokenize the text\n",
    "data_list = df_text['text_cleaned'].tolist()\n",
    "data_tokens = list(sent_to_words(data_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 34s, sys: 1.94 s, total: 3min 36s\n",
      "Wall time: 3min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create bigrams & trigrams\n",
    "bigram = gensim.models.Phrases(data_tokens, min_count=1, threshold=1)\n",
    "trigram = gensim.models.Phrases(bigram[data_tokens], threshold=1)\n",
    "\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:13\u001b[0m\n",
      "File \u001b[0;32m<timed exec>:20\u001b[0m, in \u001b[0;36mlemmatization\u001b[0;34m(texts, allowed_postags)\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/spacy/language.py:1011\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m   1009\u001b[0m     error_handler \u001b[39m=\u001b[39m proc\u001b[39m.\u001b[39mget_error_handler()\n\u001b[1;32m   1010\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1011\u001b[0m     doc \u001b[39m=\u001b[39m proc(doc, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcomponent_cfg\u001b[39m.\u001b[39;49mget(name, {}))  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1013\u001b[0m     \u001b[39m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[1;32m   1014\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE109\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/spacy/pipeline/trainable_pipe.pyx:52\u001b[0m, in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/spacy/pipeline/tok2vec.py:125\u001b[0m, in \u001b[0;36mTok2Vec.predict\u001b[0;34m(self, docs)\u001b[0m\n\u001b[1;32m    123\u001b[0m     width \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mget_dim(\u001b[39m\"\u001b[39m\u001b[39mnO\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    124\u001b[0m     \u001b[39mreturn\u001b[39;00m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39malloc((\u001b[39m0\u001b[39m, width)) \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m docs]\n\u001b[0;32m--> 125\u001b[0m tokvecs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mpredict(docs)\n\u001b[1;32m    126\u001b[0m \u001b[39mreturn\u001b[39;00m tokvecs\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/thinc/model.py:315\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X: InT) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m OutT:\n\u001b[1;32m    312\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[39m    only the output, instead of the `(output, callback)` tuple.\u001b[39;00m\n\u001b[1;32m    314\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 315\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/thinc/layers/chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     53\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[1;32m     54\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[1;32m     56\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     57\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/thinc/model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    289\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/thinc/layers/with_array.py:43\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, Xseq, is_train)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[39mreturn\u001b[39;00m model\u001b[39m.\u001b[39mlayers[\u001b[39m0\u001b[39m](Xseq, is_train)\n\u001b[1;32m     42\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 43\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(Tuple[SeqT, Callable], _list_forward(model, Xseq, is_train))\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/thinc/layers/with_array.py:78\u001b[0m, in \u001b[0;36m_list_forward\u001b[0;34m(model, Xs, is_train)\u001b[0m\n\u001b[1;32m     76\u001b[0m lengths \u001b[39m=\u001b[39m NUMPY_OPS\u001b[39m.\u001b[39masarray1i([\u001b[39mlen\u001b[39m(seq) \u001b[39mfor\u001b[39;00m seq \u001b[39min\u001b[39;00m Xs])\n\u001b[1;32m     77\u001b[0m Xf \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mflatten(Xs, pad\u001b[39m=\u001b[39mpad)\n\u001b[0;32m---> 78\u001b[0m Yf, get_dXf \u001b[39m=\u001b[39m layer(Xf, is_train)\n\u001b[1;32m     80\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbackprop\u001b[39m(dYs: ListXd) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ListXd:\n\u001b[1;32m     81\u001b[0m     dYf \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mflatten(dYs, pad\u001b[39m=\u001b[39mpad)\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/thinc/model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    289\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/thinc/layers/chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     53\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[1;32m     54\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[1;32m     56\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     57\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/thinc/model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    289\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/thinc/layers/residual.py:41\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m         \u001b[39mreturn\u001b[39;00m d_output \u001b[39m+\u001b[39m dX\n\u001b[0;32m---> 41\u001b[0m Y, backprop_layer \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mlayers[\u001b[39m0\u001b[39;49m](X, is_train)\n\u001b[1;32m     42\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(X, \u001b[39mlist\u001b[39m):\n\u001b[1;32m     43\u001b[0m     \u001b[39mreturn\u001b[39;00m [X[i] \u001b[39m+\u001b[39m Y[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(X))], backprop\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/thinc/model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    289\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/thinc/layers/chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     53\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[1;32m     54\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[1;32m     56\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     57\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/thinc/model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    289\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/thinc/layers/chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     53\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[1;32m     54\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[1;32m     56\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     57\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "    \u001b[0;31m[... skipping similar frames: Model.__call__ at line 291 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/thinc/layers/chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     53\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[1;32m     54\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[1;32m     56\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     57\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/thinc/model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    289\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/thinc/layers/maxout.py:53\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     51\u001b[0m W \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mget_param(\u001b[39m\"\u001b[39m\u001b[39mW\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     52\u001b[0m W \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mreshape2f(W, nO \u001b[39m*\u001b[39m nP, nI)\n\u001b[0;32m---> 53\u001b[0m Y \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mops\u001b[39m.\u001b[39;49mgemm(X, W, trans2\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     54\u001b[0m Y \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mreshape1f(b, nO \u001b[39m*\u001b[39m nP)\n\u001b[1;32m     55\u001b[0m Z \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mreshape3f(Y, Y\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], nO, nP)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Remove Stop Words\n",
    "#data_tokens_nostops = remove_stopwords(data_tokens)\n",
    "\n",
    "# Create n-grams\n",
    "data_words_bigrams = make_bigrams(data_tokens)\n",
    "data_words_trigrams = make_trigrams(data_tokens)\n",
    "\n",
    "# Combine tokens and n-grams\n",
    "# data_tokens_cobnined = data_tokens_nostops + data_words_bigrams + data_words_trigrams\n",
    "data_tokens_cobnined = data_words_trigrams\n",
    "\n",
    "# Lemmatize text keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_tokens_cobnined, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(*data_lemmatized[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = '/home/anthony/projects/nlp_runtime/'\n",
    "\n",
    "# save the limmatized data to txt\n",
    "path = checkpoint_path + '/' + 'data_lemmatized.txt'\n",
    "with open(path, 'w') as f:\n",
    "    for item in data_lemmatized:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # read the limmatized data from txt\n",
    "# path = checkpoint_path + '/' + 'data_lemmatized.txt'\n",
    "# with open(path, 'r') as f:\n",
    "#     data_read = f.read().splitlines()\n",
    "\n",
    "# read each element (a str) of data_read to a list; append to data_lemmatized\n",
    "data_lemmatized = []\n",
    "\n",
    "def string_to_list(str):\n",
    "    # revemo al \" and []\n",
    "    str = str.replace('\"', '')\n",
    "    str = str.replace('\\'', '')\n",
    "    str = str.replace('[', '')\n",
    "    str = str.replace(']', '')\n",
    "    # split by ', '\n",
    "    output_list = str.split(', ')\n",
    "    return output_list\n",
    "\n",
    "for i in range(len(data_read)):\n",
    "    data_lemmatized.append(string_to_list(data_read[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Creating the term dictionary of our courpus, where every unique term is assigned an index. \n",
    "dictionary = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Converting list of documents (corpus) into Document Term Matrix using dictionary prepared above.\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in data_lemmatized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_processors = multiprocessing.cpu_count()\n",
    "workers = num_processors-1\n",
    "print(f'Using {workers} workers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supporting function\n",
    "def compute_coherence_values(corpus, dictionary, k, a, b):\n",
    "    \n",
    "    lda_model = LdaMulticore(corpus=doc_term_matrix,\n",
    "                       id2word=dictionary,\n",
    "                       num_topics=k,\n",
    "                       random_state=100,                  \n",
    "                       passes=10,\n",
    "                       alpha=a,\n",
    "                       eta=b,\n",
    "                       workers=workers)\n",
    "    \n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=dictionary, coherence='c_v')\n",
    "    \n",
    "    return coherence_model_lda.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {}\n",
    "grid['Validation_Set'] = {}\n",
    "\n",
    "# Topics range\n",
    "min_topics = 2\n",
    "max_topics = 10\n",
    "step_size = 1\n",
    "topics_range = range(min_topics, max_topics+1, step_size)\n",
    "\n",
    "# Alpha parameter\n",
    "alpha = ['asymmetric'] # Run for number of topics only\n",
    "\n",
    "# Beta parameter\n",
    "beta = ['auto'] # Run for number of topics only\n",
    "\n",
    "# Validation sets\n",
    "num_of_docs = len(doc_term_matrix)\n",
    "corpus_sets = [# gensim.utils.ClippedCorpus(doc_term_matrix, num_of_docs*0.25), \n",
    "               # gensim.utils.ClippedCorpus(doc_term_matrix, num_of_docs*0.5), \n",
    "               # gensim.utils.ClippedCorpus(doc_term_matrix, num_of_docs*0.75), \n",
    "               doc_term_matrix]\n",
    "\n",
    "corpus_title = ['100% Corpus']\n",
    "model_results = {\n",
    "                 'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''%%time \n",
    "\n",
    "itr = 0\n",
    "itr_total = len(beta)*len(alpha)*len(topics_range)*len(corpus_title)\n",
    "print(f'LDA will execute {itr_total} iterations')\n",
    "\n",
    "# iterate through hyperparameters\n",
    "for i in tqdm(range(len(corpus_sets))):\n",
    "    # iterate through number of topics\n",
    "    for k in topics_range:\n",
    "        # iterate through alpha values\n",
    "        #tic()\n",
    "        for a in alpha:\n",
    "            # iterare through beta values\n",
    "            for b in beta:\n",
    "                # get the coherence score for the given parameters\n",
    "                itr += 1\n",
    "                cv = compute_coherence_values(corpus=corpus_sets[i], dictionary=dictionary,\n",
    "                                              k=k, a=a, b=b)\n",
    "                # Save the model results\n",
    "                model_results['Topics'].append(k)\n",
    "                model_results['Alpha'].append(a)\n",
    "                model_results['Beta'].append(b)\n",
    "                model_results['Coherence'].append(cv)\n",
    "                pct_completed = round((itr / itr_total * 100),1)\n",
    "        print(f'Completed model based on {k} LDA topics. Finished {pct_completed}% of LDA runs')\n",
    "\n",
    "lda_tuning = pd.DataFrame(model_results)     '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "def compute_coherence_values(corpus, dictionary, k, a, b):\n",
    "    lda_model = LdaMulticore(corpus=corpus,\n",
    "                       id2word=dictionary,\n",
    "                       num_topics=k,\n",
    "                       random_state=100,                  \n",
    "                       passes=10,\n",
    "                       alpha=a,\n",
    "                       eta=b,\n",
    "                       workers=workers)\n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=dictionary, coherence='c_v')\n",
    "    return coherence_model_lda.get_coherence()\n",
    "\n",
    "itr = 0\n",
    "itr_total = len(beta)*len(alpha)*len(topics_range)*len(corpus_title)\n",
    "print(f'LDA will execute {itr_total} iterations')\n",
    "\n",
    "# iterate through hyperparameters\n",
    "for i in tqdm(range(len(corpus_sets))):\n",
    "    # iterate through number of topics\n",
    "    for k in topics_range:\n",
    "        # iterate through alpha values\n",
    "        #tic()\n",
    "        for a in alpha:\n",
    "            # iterate through beta values\n",
    "            jobs = []\n",
    "            for b in beta:\n",
    "                itr += 1\n",
    "                # run each beta value in parallel\n",
    "                job = delayed(compute_coherence_values)(corpus=corpus_sets[i], dictionary=dictionary,\n",
    "                                                  k=k, a=a, b=b)\n",
    "                jobs.append(job)\n",
    "            # compute coherence scores in parallel and save results\n",
    "            coherences = Parallel(n_jobs=min(8, len(jobs)))(jobs)\n",
    "            for b, cv in zip(beta, coherences):\n",
    "                model_results['Topics'].append(k)\n",
    "                model_results['Alpha'].append(a)\n",
    "                model_results['Beta'].append(b)\n",
    "                model_results['Coherence'].append(cv)\n",
    "            pct_completed = round((itr / itr_total * 100),1)\n",
    "        print(f'Completed model based on {k} LDA topics. Finished {pct_completed}% of LDA runs')\n",
    "\n",
    "lda_tuning = pd.DataFrame(model_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best LDA parameters\n",
    "lda_tuning.sort_values(by=['Coherence'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_tuning.plot(x ='Topics', y='Coherence', kind = 'line', xticks=range(1,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_tuning_best = lda_tuning.sort_values(by=['Coherence'], ascending=False).head(1)\n",
    "\n",
    "\n",
    "tuned_topics = int(lda_tuning_best['Topics'].to_string(index=False))\n",
    "\n",
    "\n",
    "# Since the values for Alpha and Beta can be float, symmetric and asymmetric, we will either strip or convert to float\n",
    "try:\n",
    "    tuned_alpha = float(lda_tuning_best['Alpha'].to_string(index=False))\n",
    "except:\n",
    "    tuned_alpha = lda_tuning_best['Alpha'].to_string(index=False).strip()\n",
    "    \n",
    "\n",
    "try:\n",
    "    tuned_beta = float(lda_tuning_best['Beta'].to_string(index=False))\n",
    "except:\n",
    "    tuned_beta = lda_tuning_best['Beta'].to_string(index=False).strip()    \n",
    "    \n",
    "print(f'Best Parameters: Topics: {tuned_topics}, Alpha: {tuned_alpha}, Beta: {tuned_beta}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "tuned_lda_model = LdaMulticore(corpus=doc_term_matrix,\n",
    "                       id2word=dictionary,\n",
    "                       #num_topics=tuned_topics,\n",
    "                       num_topics=4,\n",
    "                       random_state=100,\n",
    "                       passes=10,\n",
    "                       alpha=tuned_alpha,\n",
    "                       eta=tuned_beta,\n",
    "                       workers = workers)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=tuned_lda_model, texts=data_lemmatized, dictionary=dictionary, coherence='c_v')\n",
    "print('\\nCoherence Score: ', coherence_model_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "lda_display = gensimvis.prepare(tuned_lda_model, doc_term_matrix, dictionary, sort_topics=False, mds='mmds')\n",
    "pyLDAvis.display(lda_display)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
