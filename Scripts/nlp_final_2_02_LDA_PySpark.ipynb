{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on Dataproc PySpark\n",
    "\n",
    "1. https://medium.com/trustyou-engineering/topic-modelling-with-pyspark-and-spark-nlp-\n",
    "2. https://github.com/JohnSnowLabs/spark-nlp/issues/232\n",
    "    - issue: TypeError because the path for sparknlp is missung; the jar path is not called\n",
    "    - solution: create a new conda envrionment named sparknlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/15 04:22:45 INFO SparkEnv: Registering MapOutputTracker\n",
      "23/05/15 04:22:45 INFO SparkEnv: Registering BlockManagerMaster\n",
      "23/05/15 04:22:45 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "23/05/15 04:22:45 INFO SparkEnv: Registering OutputCommitCoordinator\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3.3.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sparknlp\n",
    "spark = sparknlp.start()\n",
    "\n",
    "#Ensure we are using the right kernel\n",
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pwd\n",
    "import os\n",
    "\n",
    "# Google Bucket\n",
    "# file name checkpoint_0512_sent_split.parquet\n",
    "path_bucket = 'gs://msca-sp23-bucket/nlp_data'\n",
    "dataPath = path_bucket + '/' + 'df_cleaned_0514.parquet'\n",
    "#runtime_path = '/home/jupyter/data/nlp_final'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\",True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.6 ms, sys: 0 ns, total: 7.6 ms\n",
      "Wall time: 4.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_raw = spark.read.parquet(dataPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- url: string (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- text_split: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_raw.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>url</th><th>date</th><th>title</th><th>text_split</th><th>text</th></tr>\n",
       "<tr><td>http://en.people....</td><td>2021-03-18</td><td>Artificial intell...</td><td>[Chinese Japanese...</td><td>Chinese Japanese ...</td></tr>\n",
       "<tr><td>http://newsparlia...</td><td>2020-02-27</td><td>Children With Aut...</td><td>[ Children With A...</td><td> Children With Au...</td></tr>\n",
       "<tr><td>http://www.datawe...</td><td>2021-03-26</td><td>Forget ML, AI and...</td><td>[Forget ML, AI an...</td><td>Forget ML, AI and...</td></tr>\n",
       "<tr><td>http://www.homeof...</td><td>2021-03-10</td><td>Strategy Analytic...</td><td>[Strategy Analyti...</td><td>Strategy Analytic...</td></tr>\n",
       "<tr><td>http://www.itbusi...</td><td>2020-10-20</td><td>Olympus to Suppor...</td><td>[Search for:   Ho...</td><td>Search for:   Hom...</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------------------+----------+--------------------+--------------------+--------------------+\n",
       "|                 url|      date|               title|          text_split|                text|\n",
       "+--------------------+----------+--------------------+--------------------+--------------------+\n",
       "|http://en.people....|2021-03-18|Artificial intell...|[Chinese Japanese...|Chinese Japanese ...|\n",
       "|http://newsparlia...|2020-02-27|Children With Aut...|[ Children With A...| Children With Au...|\n",
       "|http://www.datawe...|2021-03-26|Forget ML, AI and...|[Forget ML, AI an...|Forget ML, AI and...|\n",
       "|http://www.homeof...|2021-03-10|Strategy Analytic...|[Strategy Analyti...|Strategy Analytic...|\n",
       "|http://www.itbusi...|2020-10-20|Olympus to Suppor...|[Search for:   Ho...|Search for:   Hom...|\n",
       "+--------------------+----------+--------------------+--------------------+--------------------+"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select data\n",
    "text_col = 'text'\n",
    "news_df = df_raw.select(text_col).filter(F.col(text_col).isNotNull())\n",
    "#news_text.limit(5)\n",
    "\n",
    "import re\n",
    "# remove spaces from column names\n",
    "#new_cols = [F.col(column).alias(re.sub('\\s*', '', column)) for column in news_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "news_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemma_antbnc download started this may take some time.\n",
      "Approximate size to download 907.6 KB\n",
      "[ | ]lemma_antbnc download started this may take some time.\n",
      "Approximate size to download 907.6 KB\n",
      "Download done! Loading the resource.\n",
      "[ / ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "# build pipelines\n",
    "documentAssembler = DocumentAssembler() \\\n",
    "                     .setInputCol(text_col) \\\n",
    "                     .setOutputCol('document')\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "             .setInputCols(['document']) \\\n",
    "             .setOutputCol('tokenized')\n",
    "\n",
    "normalizer = Normalizer() \\\n",
    "             .setInputCols(['tokenized']) \\\n",
    "             .setOutputCol('normalized') \\\n",
    "             .setLowercase(True)\n",
    "\n",
    "lemmatizer = LemmatizerModel.pretrained() \\\n",
    "             .setInputCols(['normalized']) \\\n",
    "             .setOutputCol('lemmatized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "eng_stopwords = stopwords.words('english')\n",
    "stopwords_cleaner = StopWordsCleaner() \\\n",
    "     .setInputCols(['lemmatized']) \\\n",
    "     .setOutputCol('no_stop_lemmatized') \\\n",
    "     .setStopWords(eng_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_anc download started this may take some time.\n",
      "Approximate size to download 3.9 MB\n",
      "[ | ]pos_anc download started this may take some time.\n",
      "Approximate size to download 3.9 MB\n",
      "Download done! Loading the resource.\n",
      "[ / ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:===================================================>    (11 + 1) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ — ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "pos_tagger = PerceptronModel.pretrained('pos_anc') \\\n",
    "     .setInputCols(['document', 'lemmatized']) \\\n",
    "     .setOutputCol('pos')\n",
    "\n",
    "allowed_tags = ['<JJ>+<NN>', '<NN>+<NN>']\n",
    "\n",
    "chunker = Chunker() \\\n",
    "     .setInputCols(['document', 'pos']) \\\n",
    "     .setOutputCol('ngrams') \\\n",
    "     .setRegexParsers(allowed_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "finisher = Finisher() \\\n",
    "     .setInputCols(['ngrams']) # some bugs with unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline() \\\n",
    "     .setStages([documentAssembler,\n",
    "                 tokenizer,\n",
    "                 normalizer,\n",
    "                 lemmatizer,\n",
    "                 stopwords_cleaner,\n",
    "                 pos_tagger,\n",
    "                 chunker,\n",
    "                 finisher])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.util.SizeEstimator$ (file:/usr/lib/spark/jars/spark-core_2.12-3.3.0.jar) to field java.util.regex.Pattern.pattern\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.util.SizeEstimator$\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 101 ms, sys: 16.9 ms, total: 118 ms\n",
      "Wall time: 1.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "processed_news = pipeline.fit(news_df).transform(news_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>finished_ngrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chinese Japanese French Spanish Russian Arabic Korean German Portuguese Thursday, March 18, 2021 Home     Artificial intelligence improves parking efficiency in Chinese cities By Liu Shiyao  People's Daily  09:16, March 18, 2021 Photo taken on July 1, 2019, shows a sign for electronic toll collection  ETC  newly set up at a roadside parking space on Yangzhuang road, Shijingshan district, Beijing. Some urban areas of the city started to use ETC system for roadside parking spaces since July 1,...</td>\n",
       "      <td>[Chinese Japanese French Spanish Russian Arabic, Korean German, Artificial intelligence, Chinese cities, Daily  09:16, March, electronic toll, Shijingshan district, urban areas, Daily Online/Li Wenming, artificial intelligence, electronic toll, significant improvement, normal lanes, mute time, wider,  Wang, smart roadside, smart parking, intelligent system, full play, integrate AI, real economy, Traditional parking, actual needs, technical capacity, many deficiencies, traditional parking, ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Children With Autism Saw Their Learning and Social Skills Boosted After Playing With This AI Robot   News Parliament          Children With Autism Saw Their Learning and Social Skills Boosted After Playing With This AI Robot        Author Recent Posts   admin  Latest posts by admin  see all   Mansplaining in conferences: How can we get him to forestall?   February 27, 2020   Coronavirus Could Explode in the U.S. Overnight Like it Did in Italy   February 27, 2020   Levi Strauss marks the nex...</td>\n",
       "      <td>[Social Skills, Social Skills, Recent Posts, Latest posts, next phase, corporate paid, social talents, such era, average autism, assistive robotic, named, incorrect Kiwi, Robotics discovered, higher social talents, mentary. Cameras, engagement ranged, possible distractions, domestic home, real time, educational and/o, therapeutic activity, proper, lead, assistive robotic. Haotian, similar manner, neurotypical other folks, individualized products, such youngsters, social talents, outstanding ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Forget ML, AI and Industry 4.0   obsolescence should be your focus   26 February 2021   Test   Rework Solutions   Dataweek Home About us Back issues / E book / PDF EMP Handbook Subscribe Advertise   Editor's Choice   Multimedia, Videos   Analogue, Mixed Signal, LSI   Circuit   System Protection   Computer/Embedded Technology   Design Automation   DSP, Micros   Memory   Electronics Technology   Enclosures, Racks, Cabinets   Panel Products   Events   Interconnection   Manufacturing / Productio...</td>\n",
       "      <td>[Micros   Memory, Passive Components, Programmable Logic, Smart Home, Wireless, IoT, friendly version, new era, accelerated transformation, last eighteen, new timeline, careful planning, longer exists, pompous meeting, selected leading, green energy, due course.Whomeve, big businesses, automotive, defence, new installations, smaller turbines, multiple suppliers, biggest change, industrial asset, recent years, many rail, chief mechanical engineer, electronic failures, ideal means, cheap solut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Strategy Analytics: 71  of Smartphones Sold Globally in 2021 will be AI Powered   Consumer Electronics Net   Skip to content Search for:   HomeNewsStrategy Analytics: 71  of Smartphones Sold Globally in 2021 will be AI Powered                                     News                                 Strategy Analytics: 71  of Smartphones Sold Globally in 2021 will be AI Powered                     7 hours ago               BOSTON BUSINESS WIRE Strategy Analytics in a newly published report, S...</td>\n",
       "      <td>[AI Powered, Net   Skip, Global Artificial Intelligence, Artificial Intelligence, rapidly implemented, various functions, intelligent power, virtual assistants, important technology, putational power, Analytics estimates, Associate Director, Ukonaho.  Advantages, lower latency, overall lower power, Artificial Intelligence, deep learning, Artificial Intelligence, key technology, higher end, important tasks, longer battery, efficient power, digital assistants, other tasks, useful tools, own pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Search for:   Home2020OctoberOlympus to Support Endoscopic AI Diagnosis Education for Doctors in India and to Launch AI Diagnostic Support Application                                     News                                 Olympus to Support Endoscopic AI Diagnosis Education for Doctors in India and to Launch AI Diagnostic Support Application TOKYO, Oct 20, 2020    ACN Newswire     Olympus Corporation took part in a ground breaking project as a business promoter, in cooperation with the Min...</td>\n",
       "      <td>[Endoscopic AI, Diagnostic Support, Endoscopic AI, Diagnostic Support, Internal Affairs, MIC , entitled, International Expansion, High Magnifying, few endoscopists, diagnostic support, major medical institution, Asian Institute, Northern Yokohama, differential diagnosis, next generation, Internal Affairs, medical care, future leaders, last year, diagnostic support, endoscopic diagnostic support, enables observation, real time, optical magnification, real time, ultra high magnifying, neoplast...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  text   \n",
       "0  Chinese Japanese French Spanish Russian Arabic Korean German Portuguese Thursday, March 18, 2021 Home     Artificial intelligence improves parking efficiency in Chinese cities By Liu Shiyao  People's Daily  09:16, March 18, 2021 Photo taken on July 1, 2019, shows a sign for electronic toll collection  ETC  newly set up at a roadside parking space on Yangzhuang road, Shijingshan district, Beijing. Some urban areas of the city started to use ETC system for roadside parking spaces since July 1,...  \\\n",
       "1   Children With Autism Saw Their Learning and Social Skills Boosted After Playing With This AI Robot   News Parliament          Children With Autism Saw Their Learning and Social Skills Boosted After Playing With This AI Robot        Author Recent Posts   admin  Latest posts by admin  see all   Mansplaining in conferences: How can we get him to forestall?   February 27, 2020   Coronavirus Could Explode in the U.S. Overnight Like it Did in Italy   February 27, 2020   Levi Strauss marks the nex...   \n",
       "2  Forget ML, AI and Industry 4.0   obsolescence should be your focus   26 February 2021   Test   Rework Solutions   Dataweek Home About us Back issues / E book / PDF EMP Handbook Subscribe Advertise   Editor's Choice   Multimedia, Videos   Analogue, Mixed Signal, LSI   Circuit   System Protection   Computer/Embedded Technology   Design Automation   DSP, Micros   Memory   Electronics Technology   Enclosures, Racks, Cabinets   Panel Products   Events   Interconnection   Manufacturing / Productio...   \n",
       "3  Strategy Analytics: 71  of Smartphones Sold Globally in 2021 will be AI Powered   Consumer Electronics Net   Skip to content Search for:   HomeNewsStrategy Analytics: 71  of Smartphones Sold Globally in 2021 will be AI Powered                                     News                                 Strategy Analytics: 71  of Smartphones Sold Globally in 2021 will be AI Powered                     7 hours ago               BOSTON BUSINESS WIRE Strategy Analytics in a newly published report, S...   \n",
       "4  Search for:   Home2020OctoberOlympus to Support Endoscopic AI Diagnosis Education for Doctors in India and to Launch AI Diagnostic Support Application                                     News                                 Olympus to Support Endoscopic AI Diagnosis Education for Doctors in India and to Launch AI Diagnostic Support Application TOKYO, Oct 20, 2020    ACN Newswire     Olympus Corporation took part in a ground breaking project as a business promoter, in cooperation with the Min...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       finished_ngrams  \n",
       "0  [Chinese Japanese French Spanish Russian Arabic, Korean German, Artificial intelligence, Chinese cities, Daily  09:16, March, electronic toll, Shijingshan district, urban areas, Daily Online/Li Wenming, artificial intelligence, electronic toll, significant improvement, normal lanes, mute time, wider,  Wang, smart roadside, smart parking, intelligent system, full play, integrate AI, real economy, Traditional parking, actual needs, technical capacity, many deficiencies, traditional parking, ma...  \n",
       "1  [Social Skills, Social Skills, Recent Posts, Latest posts, next phase, corporate paid, social talents, such era, average autism, assistive robotic, named, incorrect Kiwi, Robotics discovered, higher social talents, mentary. Cameras, engagement ranged, possible distractions, domestic home, real time, educational and/o, therapeutic activity, proper, lead, assistive robotic. Haotian, similar manner, neurotypical other folks, individualized products, such youngsters, social talents, outstanding ...  \n",
       "2  [Micros   Memory, Passive Components, Programmable Logic, Smart Home, Wireless, IoT, friendly version, new era, accelerated transformation, last eighteen, new timeline, careful planning, longer exists, pompous meeting, selected leading, green energy, due course.Whomeve, big businesses, automotive, defence, new installations, smaller turbines, multiple suppliers, biggest change, industrial asset, recent years, many rail, chief mechanical engineer, electronic failures, ideal means, cheap solut...  \n",
       "3  [AI Powered, Net   Skip, Global Artificial Intelligence, Artificial Intelligence, rapidly implemented, various functions, intelligent power, virtual assistants, important technology, putational power, Analytics estimates, Associate Director, Ukonaho.  Advantages, lower latency, overall lower power, Artificial Intelligence, deep learning, Artificial Intelligence, key technology, higher end, important tasks, longer battery, efficient power, digital assistants, other tasks, useful tools, own pe...  \n",
       "4  [Endoscopic AI, Diagnostic Support, Endoscopic AI, Diagnostic Support, Internal Affairs, MIC , entitled, International Expansion, High Magnifying, few endoscopists, diagnostic support, major medical institution, Asian Institute, Northern Yokohama, differential diagnosis, next generation, Internal Affairs, medical care, future leaders, last year, diagnostic support, endoscopic diagnostic support, enables observation, real time, optical magnification, real time, ultra high magnifying, neoplast...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_news.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization with PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "tfizer = CountVectorizer(inputCol='finished_ngrams',\n",
    "                         outputCol='tf_features')\n",
    "tf_model = tfizer.fit(processed_news)\n",
    "tf_result = tf_model.transform(processed_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import IDF\n",
    "idfizer = IDF(inputCol='tf_features', \n",
    "              outputCol='tf_idf_features')\n",
    "idf_model = idfizer.fit(tf_result)\n",
    "tfidf_result = idf_model.transform(tf_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import LDA\n",
    "num_topics = 6\n",
    "max_iter = 10\n",
    "lda = LDA(k=num_topics, \n",
    "          maxIter=max_iter, \n",
    "          featuresCol='tf_idf_features')\n",
    "lda_model = lda.fit(tfidf_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = tf_model.vocabulary\n",
    "def get_words(token_list):\n",
    "    return [vocab[token_id] for token_id in token_list]\n",
    "udf_to_words = F.udf(get_words, T.ArrayType(T.StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_words = 6\n",
    "topics = lda_model\n",
    "     .describeTopics(num_top_words)\n",
    "     .withColumn('topicWords', udf_to_words(F.col('termIndices')))\n",
    "topics.select('topic', 'topicWords').show(truncate=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sparknlp",
   "language": "python",
   "name": "sparknlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
